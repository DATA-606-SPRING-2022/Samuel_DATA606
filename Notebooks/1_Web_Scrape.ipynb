{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - Web Scrape",
      "provenance": [],
      "authorship_tag": "ABX9TyPdnClTQQt7Zdvx+EmLhNZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skbetz54/Samuel_DATA606/blob/main/Notebooks/1_Web_Scrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA 606 - Web Scrape**\n",
        "\n",
        "The purpose of this notebook is to gather the news articles that will be used in the sentiment analysis. There are three main sites that I will be pulling news articles: AP News, CNN, and Fox News. Each site has a different strategy for creating the articles' hyperlinks (detailed below), so the processes of scraping each site will differ slightly. \n",
        "\n",
        "There are several steps to this process to get the data fit for my analysis:\n",
        "\n",
        "1. Downloading the (political) news articles and extracting only the first paragraph.\n",
        "2. Storing the articles' paragraphs in a Pandas dataframe. It will be stored in a columnar table, with each entry (row) being an individual article. The rows will include information such as the news site (to determine the varying fear levels across news sites), date of publishing (to see if the level of fear has changed over time), and the text of the article's first paragraph (to be used in the actual sentiment analysis). \n",
        "3. Once the data is stored I can start preprocessing data (tokenization, stemming, etc.), which will follow in another notebook."
      ],
      "metadata": {
        "id": "zrjV7olOtJ36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Library Imports**\n",
        "\n",
        "To scrape these sites and in turn store them in a usable format, we first need to import various Python libraries. The main tool we will use, since most of the news articles are text within, is the parsing library BeautifulSoup"
      ],
      "metadata": {
        "id": "r1LHj5bkDH6B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jN0mH0j2s6Am"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **AP News Web Scrape**"
      ],
      "metadata": {
        "id": "EgtncLffDFQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o3H8w9-cFb4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N9MNzaoHFb2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fEafU4RsFbzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sMG_h_n0Fbk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN Web Scrape**"
      ],
      "metadata": {
        "id": "Bj9ZcTx2EdLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U__ZRAK4Fcgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l8yvVt-0FceD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W_SR-2n4Fcba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WxeqKzHPFcYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fox News Web Scrape**"
      ],
      "metadata": {
        "id": "ma6CIceEEc2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-ata0ZuEFdYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6RIbB214FdWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_aX_E0uVFdT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "44rE3Zr5FdRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zfJQ3lzdFdOu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}